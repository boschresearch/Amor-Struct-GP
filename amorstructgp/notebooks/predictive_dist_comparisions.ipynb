{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction plots of trained amortization network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amorstructgp.models.gp_model_amortized_structured import GPModelAmortizedStructured\n",
    "from amorstructgp.models.gp_model_amortized_ensemble import GPModelAmortizedEnsemble\n",
    "from amorstructgp.config.models.gp_model_amortized_structured_config import PaperAmortizedStructuredConfig,AmortizedStructuredWithMaternConfig\n",
    "from amorstructgp.config.models.gp_model_amortized_ensemble_config import PaperAmortizedEnsembleConfig,AmortizedEnsembleWithMaternConfig\n",
    "from amorstructgp.models.model_factory import ModelFactory\n",
    "from amorstructgp.config.nn.amortized_infer_models_configs import WiderCrossAttentionKernelEncSharedDatasetEncMLPWrapperAmortizedModelConfig,SmallerStandardNoDropoutCrossAttentionKernelEncSharedDatasetEncMLPWrapperAmortizedModelConfig,SmallerStandardSmallNoiseBoundNoDropoutCrossAttentionKernelEncSharedDatasetEncMLPWrapperAmortizedModelConfig\n",
    "from amorstructgp.utils.enums import PredictionQuantity\n",
    "from amorstructgp.gp.base_symbols import BaseKernelTypes\n",
    "from amorstructgp.data_generators.simulator import Simulator\n",
    "from amorstructgp.config.prior_parameters import NOISE_VARIANCE_EXPONENTIAL_LAMBDA\n",
    "from amorstructgp.gp.base_kernels import transform_kernel_list_to_expression\n",
    "from amorstructgp.utils.plotter import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PAPER_MODEL = False\n",
    "PATH_TO_PRETRAINED=\"\"\n",
    "paper_model_path = os.path.join(PATH_TO_PRETRAINED,\"main_state_dict_paper.pth\")\n",
    "matern_model_path = os.path.join(PATH_TO_PRETRAINED,\"main_state_dict_with_matern.pth\")\n",
    "if USE_PAPER_MODEL:\n",
    "    model_path = paper_model_path\n",
    "else:\n",
    "    model_path = matern_model_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PAPER_MODEL:\n",
    "    amortized_model_config = PaperAmortizedStructuredConfig(checkpoint_path=model_path)\n",
    "else:\n",
    "    amortized_model_config = AmortizedStructuredWithMaternConfig(checkpoint_path=model_path)\n",
    "model = ModelFactory.build(amortized_model_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amorstructgp.utils.gaussian_mixture_density import EntropyApproximation\n",
    "if USE_PAPER_MODEL:\n",
    "    amortized_ensemble_model_config = PaperAmortizedEnsembleConfig(checkpoint_path=model_path)\n",
    "else:\n",
    "    amortized_ensemble_model_config = AmortizedEnsembleWithMaternConfig(checkpoint_path=model_path)\n",
    "ensemble = ModelFactory.build(amortized_ensemble_model_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Kernel configurations ############\n",
    "\n",
    "# Kernel from which data is generated - inner list is interpreted as sum (see paper)\n",
    "simulator_kernel_list = [[BaseKernelTypes.MATERN52,BaseKernelTypes.LIN]] \n",
    "\n",
    "# a collection of possible kernel structures (each represented as nested list - here only 1D data is considered so the first list over dimension has only one element)\n",
    "input_kernel_list_1 = [[BaseKernelTypes.MATERN52]]\n",
    "input_kernel_list_2 = [[BaseKernelTypes.LIN]]\n",
    "input_kernel_list_3 = [[BaseKernelTypes.PER]]\n",
    "input_kernel_list_4 = [[BaseKernelTypes.SE_MULT_LIN]]\n",
    "input_kernel_list_5 = [[BaseKernelTypes.LIN_MULT_PER]]\n",
    "input_kernel_list_6 = [[BaseKernelTypes.SE,BaseKernelTypes.LIN]]\n",
    "input_kernel_list_7 = [[BaseKernelTypes.PER,BaseKernelTypes.LIN]]\n",
    "input_kernel_list_8 = [[BaseKernelTypes.PER,BaseKernelTypes.SE_MULT_LIN,BaseKernelTypes.LIN]]\n",
    "input_kernel_list_9 = [[BaseKernelTypes.SE,BaseKernelTypes.LIN,BaseKernelTypes.SE_MULT_LIN]]\n",
    "input_kernel_list_10= [[BaseKernelTypes.LIN,BaseKernelTypes.SE_MULT_LIN]]\n",
    "\n",
    "# here you can configure which kernels should be tried - prediction will loop over this list \n",
    "input_kernel_lists =[input_kernel_list_1]\n",
    "\n",
    "# configuration of ensemble of kernel strucutres\n",
    "ensemble_kernel_list = [input_kernel_list_1,input_kernel_list_2,input_kernel_list_3,input_kernel_list_4,input_kernel_list_5,input_kernel_list_6,input_kernel_list_7,input_kernel_list_8,input_kernel_list_9,input_kernel_list_10]\n",
    "\n",
    "########### Dataset configurations ###########\n",
    "\n",
    "# range from which gt data is generated - input data of amortization should lie between 0.0 and 1.0 but test data can lie outside\n",
    "data_a = -0.5\n",
    "data_b = 1.5 \n",
    "\n",
    "n_data = 10 # number of training datapoint - uniform random in (0.0,1.0)\n",
    "n_test = 400 # number of test datapoints - uniform random in (data_a,data_b)\n",
    "observation_noise = 0.05 # obersation noise that is added to the data\n",
    "\n",
    "########## Model that should be printed ###########\n",
    "\n",
    "add_ml_model = True # if predictive dist of standard ML (with repeated optimitation) should be included\n",
    "add_gt_model = True # if gt GP predictive dist should be included\n",
    "add_ensemble = True # if amortized ensemble predictive dist should be included\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize GP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amorstructgp.config.kernels.gpytorch_kernels.elementary_kernels_pytorch_configs import BasicRBFPytorchConfig,RBFWithPriorPytorchConfig\n",
    "from amorstructgp.config.models.gp_model_gpytorch_config import BasicGPModelPytorchConfig,GPModelPytorchMultistartConfig\n",
    "gp_model_config  = GPModelPytorchMultistartConfig(kernel_config=RBFWithPriorPytorchConfig(input_dimension=1))\n",
    "gp_model_config.add_constant_mean_function = False\n",
    "gp_model_config.set_prior_on_observation_noise=True\n",
    "gp_model_gt_config  = BasicGPModelPytorchConfig(kernel_config=BasicRBFPytorchConfig(input_dimension=0))\n",
    "gp_model_gt_config.add_constant_mean_function = False\n",
    "gp_model_gt_config.optimize_hps=False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = random.randint(0,10000)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "n_sim = 500\n",
    "simulator = Simulator(data_a,data_b,NOISE_VARIANCE_EXPONENTIAL_LAMBDA)\n",
    "kernel_expression = transform_kernel_list_to_expression(simulator_kernel_list)\n",
    "simulated_dataset = simulator.create_sample(n_sim,n_test,kernel_expression,observation_noise)\n",
    "simulated_dataset.add_kernel_list_gt(simulator_kernel_list)\n",
    "input_dimension = simulated_dataset.get_input_dimension()\n",
    "normalize_data = False\n",
    "x_data,y_data = simulated_dataset.get_dataset(normalized_version=normalize_data)\n",
    "y_data =np.expand_dims(y_data[(x_data >=0.0) & (x_data<=1.0)],axis=1)[:n_data]\n",
    "x_data =np.expand_dims(x_data[(x_data >=0.0) & (x_data<=1.0)],axis=1)[:n_data]\n",
    "x_test,y_test = simulated_dataset.get_test_dataset(normalized_version=normalize_data)\n",
    "_,f_test = simulated_dataset.get_ground_truth_f(normalized_version=normalize_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make inference and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amorstructgp.utils.plotter import PlotterPlotly\n",
    "from amorstructgp.models.model_factory import ModelFactory\n",
    "import gpytorch\n",
    "import time\n",
    "print(\"seed: \"+str(seed))\n",
    "\n",
    "#print(f\"n_data: {n_sim}\")\n",
    "for input_kernel_list in input_kernel_lists:\n",
    "    ## Amor model\n",
    "    model.set_kernel_list(input_kernel_list)\n",
    "    \n",
    "    kernel_parameters,noise_variances =model.get_predicted_parameters(x_data,y_data)\n",
    "    time_before_model_infer = time.perf_counter()\n",
    "    model.infer(x_data,y_data)\n",
    "    pred_mu,pred_sigma = model.predictive_dist(x_test)\n",
    "    time_after_model_infer = time.perf_counter()\n",
    "    model_time = time_after_model_infer-time_before_model_infer\n",
    "    nll_model = -1*np.mean(model.predictive_log_likelihood(x_test,y_test))\n",
    "    print(\"Predicted parameters:\")\n",
    "    print(kernel_parameters)\n",
    "    print(torch.sqrt(noise_variances))\n",
    "    print(\"GT parameters:\")\n",
    "    print(simulated_dataset.get_gt_kernel_parameter_list())\n",
    "    print(simulated_dataset.get_observation_noise())\n",
    "    ## gt model\n",
    "    n_plots = 1\n",
    "    if add_ml_model:\n",
    "        gp_model = ModelFactory.build(gp_model_config)\n",
    "        print(gp_model)\n",
    "        gp_model.kernel_module =  gpytorch.kernels.AdditiveKernel(transform_kernel_list_to_expression(input_kernel_list).get_kernel())\n",
    "        time_before_model_infer = time.perf_counter()\n",
    "        gp_model.infer(x_data,y_data)\n",
    "        pred_mu_gp,pred_sigma_gp = gp_model.predictive_dist(x_test)\n",
    "        time_after_model_infer = time.perf_counter()\n",
    "        gp_model_time = time_after_model_infer-time_before_model_infer\n",
    "        nll_gp_model = -1*np.mean(gp_model.predictive_log_likelihood(x_test,y_test))\n",
    "        gp_model.eval_log_posterior_density(x_data,y_data)\n",
    "        ml_model_index=n_plots\n",
    "        n_plots+=1\n",
    "    if add_gt_model:\n",
    "        gp_model_gt_config.initial_likelihood_noise=simulated_dataset.get_observation_noise()\n",
    "        gt_model = ModelFactory.build(gp_model_gt_config)\n",
    "        gt_model.kernel_module = simulated_dataset.get_kernel_expression_gt().get_kernel()\n",
    "        time_before_model_infer = time.perf_counter()\n",
    "        gt_model.infer(x_data,y_data)\n",
    "        pred_mu_gt,pred_sigma_gt = gt_model.predictive_dist(x_test)\n",
    "        time_after_model_infer = time.perf_counter()\n",
    "        gt_model_time = time_after_model_infer-time_before_model_infer\n",
    "        nll_gt_model = -1*np.mean(gt_model.predictive_log_likelihood(x_test,y_test))\n",
    "        gt_model_index = n_plots\n",
    "        n_plots+=1  \n",
    "    if add_ensemble:\n",
    "        ensemble.set_kernel_list(ensemble_kernel_list)\n",
    "        ensemble.fast_batch_inference=True\n",
    "        time_before_model_infer = time.perf_counter()\n",
    "        ensemble.infer(x_data,y_data)\n",
    "        pred_mu_ensemble,pred_sigma_ensemble = ensemble.predictive_dist(x_test)\n",
    "        time_after_model_infer = time.perf_counter()\n",
    "        ensemble_model_time = time_after_model_infer-time_before_model_infer\n",
    "        pred_mus_ensemble,_ = ensemble.predict(x_test)\n",
    "        nll_ensemble = -1*np.mean(ensemble.predictive_log_likelihood(x_test,y_test))\n",
    "        ensemble_index = n_plots\n",
    "        n_plots +=1\n",
    "\n",
    "\n",
    "    plotter = PlotterPlotly(n_plots,share_y=True)\n",
    "    plotter.add_gt_function(x_test,f_test,\"red\",0)\n",
    "    plotter.add_predictive_dist(np.squeeze(x_test),np.squeeze(pred_mu),np.squeeze(pred_sigma),0)\n",
    "    plotter.add_datapoints(x_data,y_data,\"limegreen\",0)\n",
    "    display(f\"NLL amor model: {nll_model}\")\n",
    "    display(f\"Time amor model: {model_time} sec\")\n",
    "    if add_ml_model:\n",
    "        plotter.add_gt_function(x_test,f_test,\"red\",ml_model_index)\n",
    "        plotter.add_predictive_dist(np.squeeze(x_test),np.squeeze(pred_mu_gp),np.squeeze(pred_sigma_gp),ml_model_index)\n",
    "        plotter.add_datapoints(x_data,y_data,\"limegreen\",ml_model_index)\n",
    "        display(f\"NLL gp model: {nll_gp_model}\")\n",
    "        display(f\"Time GP model: {gp_model_time} sec\")\n",
    "    if add_gt_model:\n",
    "        plotter.add_gt_function(x_test,f_test,\"red\",gt_model_index)\n",
    "        plotter.add_predictive_dist(np.squeeze(x_test),np.squeeze(pred_mu_gt),np.squeeze(pred_sigma_gt),gt_model_index)\n",
    "        plotter.add_datapoints(x_data,y_data,\"limegreen\",gt_model_index)\n",
    "        display(f\"NLL gt model: {nll_gt_model}\")\n",
    "        display(f\"Time gt model: {gt_model_time} sec\")\n",
    "    if add_ensemble:\n",
    "        for i in range(len(pred_mus_ensemble)):\n",
    "            plotter.add_gt_function(x_test,pred_mus_ensemble[i,:],\"fuchsia\",ensemble_index,line_opacity=1.0)\n",
    "        plotter.add_predictive_dist(np.squeeze(x_test),np.squeeze(pred_mu_ensemble),np.squeeze(pred_sigma_ensemble),ensemble_index,opacity_scale=0.7)\n",
    "        #plotter.add_gt_function(x_test,f_test,\"red\",ensemble_index)\n",
    "        plotter.add_datapoints(x_data,y_data,\"limegreen\",ensemble_index)\n",
    "        display(f\"NLL amor ensemble: {nll_ensemble}\")\n",
    "        display(f\"Time amor ensemble: {ensemble_model_time} sec\")\n",
    "    \n",
    "    #plotter.add_datapoints(x_test,y_test,\"red\",0)\n",
    "    plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9609984879b405a788741d92268f3aba3ee6f607f73ee694a640bfa1ba953bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
